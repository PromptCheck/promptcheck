# âœ… This is a minimal LLM prompt test. It checks if the assistant greets the user politely.

- id: "openrouter_greet_test_001"  # Unique identifier for this test case (optional but recommended)
  name: "Prompt responds with a polite greeting" # Human-readable name for the test
  description: "Tests a basic greeting prompt using a free model on OpenRouter (Mistral 7B Instruct)." # Optional description
  type: "llm_generation" # Type of test, currently supports "llm_generation"

  input_data: # Defines the input to the LLM
    prompt: "Briefly introduce yourself and greet the user." # The prompt text

  expected_output: # Defines expected outcomes for evaluation
    regex_pattern: "(?i)(hello|hi|hey|greetings)" # Case-insensitive match for common greetings

  metric_configs: # List of metrics to apply to the LLM's output
    - metric: "regex_match" # Specifies the regex_match metric. Uses regex_pattern from expected_output.
    - metric: "token_count" # Specifies the token_count metric
      parameters: # Optional parameters for the metric
        count_types: ["completion", "total"] # Types of token counts to report
    - metric: "latency" # Specifies the latency metric
      threshold: # Optional: defines pass/fail criteria for this metric
        value: 10000 # Maximum allowed latency in milliseconds
        operator: "<=" # Test passes if actual latency is less than or equal to this value
    - metric: "cost" # Specifies the cost metric
      # No threshold for cost in this example; it will just be reported.
      # OpenRouter may provide cost via headers for some models.

  model_config: # Configuration for the LLM to be used for this test case
    provider: "openrouter" # Specifies the LLM provider (e.g., "openai", "groq", "openrouter")
    # Using a commonly available free-tier model on OpenRouter.
    # Requires OPENROUTER_API_KEY in environment or evalloop.config.yaml.
    model_name: "mistralai/mistral-7b-instruct" # Specific model name for the provider
    parameters: # LLM call parameters (provider-specific)
      temperature: 0.7 # Controls randomness (0.0 to 2.0)
      max_tokens: 50   # Maximum number of tokens to generate in the completion
      timeout_s: 25.0  # Per-attempt timeout for the API call in seconds
      retry_attempts: 2 # Number of retry attempts for the API call

  tags: ["openrouter", "free_model", "basic_example", "greeting"] # Optional tags for filtering/grouping tests 